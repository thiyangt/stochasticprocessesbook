[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Stochastic Processes",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html#what-is-a-stochastic-process",
    "href": "intro.html#what-is-a-stochastic-process",
    "title": "1  Introduction",
    "section": "1.1 What is a Stochastic Process?",
    "text": "1.1 What is a Stochastic Process?\nFirst, let’s see what does “stochastic” mean? The meaning of “stochastic” is random. The term “process” refers to a mathematical or statistical model that describes the evolution of a random variable over time. In the study of a stochastic process, we examine a collection of random variables indexed by a certain parameter, typically time, representing the evolution of a system over a series of discrete or continuous instances.\nFor example, suppose we monitor the weather condition every hour in a day sunny, rainy, and cloudy. Then you are essentially observing a stochastic process. This process describes how the weather condition evolves over time.\nCan we describe this situation using a single random variable? No, we cannot. We need a sequence of random variables index by time as follows:\n\\(X_0\\) - weather condition from 00:00 to 01:00\n\\(X_1\\) - weather condition from 01:00 to 02:00\n.\n.\n.\n\\(X_{23}\\) - weather condition from 23:00 - 00:00\nThe above scenario can be framed as a stochastic process. Here’s how it relates to the concept of a stochastic process:\nTime index: The time index is the hour of the day as 0, 1, 2, 3, … 23. Each hour is a specific point in time.\nRandom variable: The weather conditions at each hour can be viewed as random variables. These random variables can be take different values such as sunny, rainy and cloudy. The weather conditions sunny,rainy and cloudy are called states (see Section for more information).\nIn many real life situations, observations are made over a period of time. Stochastic processes are used to model and analyze such time-dependent random phenomena, allowing you to study the probabilistic behavior and make predictions about future states based on past observations. When dealing with stochastic processes, we can address various probabilistic questions, including but not limited to:\n\nConditional probabilities: For instance, given that the weather has been cloudy for the first five hours of the day, you can use the stochastic process to estimate the likelihood of it remaining cloudy or changing to a different condition in the next hour.\nTime to an event:  For example, you can estimate how long it will take for the weather to change from cloudy to sunny.\nTransition probabilities:  For instance, you can determine the likelihood of going from a rainy day to a sunny day or vice versa.\nFrequency of Events: You can examine the frequency of specific events occurring within a given time frame.\n\nThese are just a few examples of the probabilistic questions that can be addressed using stochastic processes. The specific questions you can answer will depend on the nature of the process and the data available for analysis."
  },
  {
    "objectID": "intro.html#definition-of-a-stochastic-process",
    "href": "intro.html#definition-of-a-stochastic-process",
    "title": "1  Introduction",
    "section": "1.2 Definition of a stochastic process",
    "text": "1.2 Definition of a stochastic process\nDefinition 1\nA stochastic process is a collection of random variables \\(\\{X_t, t\\in T\\}\\) or \\({X(t), t \\in T}\\) where \\(T\\) is an index set.That is for each \\(t \\in T\\), the random variable \\(X_t\\) (or \\(X(t)\\)) is a random variable."
  },
  {
    "objectID": "intro.html#parameter-space",
    "href": "intro.html#parameter-space",
    "title": "1  Introduction",
    "section": "1.3 Parameter space",
    "text": "1.3 Parameter space\nIn definition 1, the index set \\(T\\) is called the parameter space. It is usually interpreted as a time variable, telling us when the process is measured. The parameter space can be discrete or continuous.\n\n1.3.1 Discrete-parameter process\nWhen \\(T\\) is a countable set, the process is said to be a discrete-parameter process. A discrete-parameter stochastic process is defined as follows:\n\\[\\{X_t: t \\in T\\}\\] Example: Number of Customers arriving each hour to a particular super market (Discrete Parameter Space)\nIn this scenario, you are interested in the number of customers arriving during each discrete time interval, typically on an hourly basis.\n\n\n1.3.2 Continuous-parameter space\nWhen \\(T\\) is an interval of the real line, the process is said to be a continuous-parameter process. A continuous-parameter stochastic process is defined as follows:\n\\[\\{X(t): t \\in T\\}\\]\nExample 1: Number of Customers Arriving from 8 AM to 10 PM (Continuous Parameter Space):\nIn this scenario, you are interested in the total number of customers arriving over a continuous time period, specifically from 8 AM to 10 PM."
  },
  {
    "objectID": "intro.html#state-space",
    "href": "intro.html#state-space",
    "title": "1  Introduction",
    "section": "1.4 State space",
    "text": "1.4 State space\nThe set of possible values of an individual random variable \\(X_t\\) or \\(X(t)\\) of a stochastic process is called the state space. The state space can be discrete or continuous."
  },
  {
    "objectID": "intro.html#random-variable-in-probability-theory-vs-stochastic-theory",
    "href": "intro.html#random-variable-in-probability-theory-vs-stochastic-theory",
    "title": "1  Introduction",
    "section": "1.5 Random Variable in Probability Theory vs Stochastic Theory",
    "text": "1.5 Random Variable in Probability Theory vs Stochastic Theory\n\n1.5.1 Probability theory\n\nLet \\((\\Omega, \\mathscr{F}, \\mathbb{P})\\) be a probability space. A measurable mapping \\(X: \\Omega \\rightarrow \\mathbb{R}\\) is called a random variable. The \\(X(\\omega)\\) for \\(\\omega \\in \\Omega\\) iscalled a realization of \\(X\\).\nExample:\n\n\n1.5.2 Stochastic theory\nSuppose that \\((\\Omega, \\mathscr{F}, \\mathbb{P})\\) is a probability space, the function \\(X: T \\times \\Omega \\rightarrow \\mathbb{R}\\) .\n\nWe will always assume that the cardinality of \\(T\\) is infinite, either countable or uncountable.\n\nIf \\(T=\\mathbb{Z}^+\\) then we called \\(X\\) a discrete time stochastic process.\nIf \\(I = [0,\\infty)\\), then \\(X\\) is said to be a continuous time stochastic processes."
  },
  {
    "objectID": "intro.html#sample-path-trajectory-of-a-stochastic-process",
    "href": "intro.html#sample-path-trajectory-of-a-stochastic-process",
    "title": "1  Introduction",
    "section": "1.6 Sample path (trajectory) of a stochastic process",
    "text": "1.6 Sample path (trajectory) of a stochastic process\nThe function \\(t \\rightarrow X_t(\\omega)\\) (\\(t \\rightarrow X(t)(\\omega)\\)) is called a sample path of the stochastic process. For each\nExample:"
  },
  {
    "objectID": "intro.html#types-of-stochastic-processes",
    "href": "intro.html#types-of-stochastic-processes",
    "title": "1  Introduction",
    "section": "1.7 Types of Stochastic Processes",
    "text": "1.7 Types of Stochastic Processes\nDepending on the parameter space and state space we can define four type of stochastic processes.\n1. Discrete-Parameter Discrete-State Space Stochastic Processes:\n\nParameter Space: Discrete\nState Space: Discrete\nExamples: Assessment of crop condition during routine field inspections in agriculture is categorized as: healthy, pest-infested, diseased, damaged. These field inspections are typically conducted at regular intervals, such as once a week\n\n2. Continuous-Parameter Discrete-State Space Stochastic Processes:\n\nParameter Space: Continuous\nState Space: Discrete\nExamples:\n\n3. Discrete-Parameter Continous-State Space Stochastic Processes:\n\nParameter Space: Discrete\nState Space: Continuous\nExamples:\n\n4. Continuous-Parameter Continuous-State Space Stochastic Processes:\n\nParameter Space: Continuous\nState Space: Continuous\nExamples:"
  },
  {
    "objectID": "intro.html#stationary-condition-of-a-stochastic-process",
    "href": "intro.html#stationary-condition-of-a-stochastic-process",
    "title": "1  Introduction",
    "section": "1.10 Stationary condition of a stochastic process",
    "text": "1.10 Stationary condition of a stochastic process"
  },
  {
    "objectID": "intro.html#independent-increments-condition-of-a-stochastic-process",
    "href": "intro.html#independent-increments-condition-of-a-stochastic-process",
    "title": "1  Introduction",
    "section": "1.11 Independent increments condition of a stochastic process",
    "text": "1.11 Independent increments condition of a stochastic process"
  },
  {
    "objectID": "intro.html#stationary-increments-condition-of-a-stochastic-process",
    "href": "intro.html#stationary-increments-condition-of-a-stochastic-process",
    "title": "1  Introduction",
    "section": "1.12 Stationary increments condition of a stochastic process",
    "text": "1.12 Stationary increments condition of a stochastic process"
  },
  {
    "objectID": "intro.html#stochastic-process-vs-a-deterministic-process",
    "href": "intro.html#stochastic-process-vs-a-deterministic-process",
    "title": "1  Introduction",
    "section": "1.9 Stochastic process vs a deterministic process",
    "text": "1.9 Stochastic process vs a deterministic process\nConsider the following data generating process and its visual representation. Let’s define the set of random variables as follows:\n\\(X_0\\) - value at time \\(t=1\\)\n\\(X_1\\) - value at time \\(t=2\\)\n\\(X_2\\) - value at time \\(t=3\\)\n.\n.\n.\nDo you consider Figure 1.2 as a realization of a stochastic process?\n\nt &lt;- 1:100\nxt &lt;- sin(2*pi*t)\ndf &lt;- data.frame(xt=xt, t=t)\nggplot(data=df, aes(x=t, y=xt)) + \n  geom_point() + \n  geom_line()\n\n\n\n\nFigure 1.2: Visual representation of data\n\n\n\n\nThe answer is “No”. The reason is when you observe the above R-code you can see the values are generated based on the function \\(\\sin(2 \\pi t)\\). Hence, there is no randomness associated with he random variables. This type of process is called a deterministic process."
  },
  {
    "objectID": "intro.html#stochastic-proceses-vs-time-series",
    "href": "intro.html#stochastic-proceses-vs-time-series",
    "title": "1  Introduction",
    "section": "1.8 Stochastic proceses vs Time series",
    "text": "1.8 Stochastic proceses vs Time series\nFigure Figure 1.1 shows a weekly dengue cases in Sri Lanka from 2006 - Week 52 to 2023 - Week 8. The data are available in the denguedatahub package in R (dengudatahub?). The first few rows of the dataset is shown below.\n\n\n\n\n\nyear\nweek\nstart.date\nend.date\ndistrict\ncases\n\n\n\n\n2006\n52\n2006-12-23\n2006-12-29\nColombo\n71\n\n\n2007\n1\n2006-12-30\n2007-01-05\nColombo\n40\n\n\n2007\n2\n2007-01-06\n2007-01-12\nColombo\n43\n\n\n2007\n3\n2007-01-13\n2007-01-19\nColombo\n38\n\n\n2007\n4\n2007-01-20\n2007-01-26\nColombo\n52\n\n\n2007\n5\n2007-01-27\n2007-02-02\nColombo\n69\n\n\n\n\n\nLet’s define the set of random variables as follows:\n\\(X_0\\) - Cases of dengue during the fifty second week of 2006\n\\(X_1\\) - Cases of dengue during the first week of 2007\n\\(X_2\\) - Cases of dengue during the second week of 2007\n.\n.\n.\nDo you consider Figure 1.1 as a visual representation of the above Stochastic Process?\n\nlibrary(denguedatahub) # to load data\nlibrary(ggplot2) # for plotting\ndata(srilanka_weekly_data)\nsrilanka_weekly_data |&gt; \n  dplyr::filter(district == \"Colombo\") |&gt;\nggplot2::ggplot(aes(x=start.date, y=cases)) + \n  geom_line()  + \n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") + \n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab(\"Time\")\n\n\n\n\nFigure 1.1: Weekly dengue cases in Sri Lanka from 2007 to 2023 August\n\n\n\n\nThe answer is “No”. Figure 1.1 is not a visual representation of the stochastic process. It is a realization of the above stochastic process. According to the data set in the fifty second week of 2006, there were 76 cases were reported. This is the observed value of the random variable \\(X_0\\). Similarly, the observed value of the random variable \\(X_1\\) is 40. Hence, Figure 1.1 represents the set of observed values of the the stochastic process. This is called a time series. “In other words, time series is a realization of a stochastic process. When we say a time series is a realization, we mean that it represents a specific outcome or path or trajectory of a stochastic process. A realization is essentially a particular observed sequence of values that the process can take. Therefore, when we say a time series is a realization of a stochastic process, we are highlighting that the observed sequence of data points in a time series is one possible outcome of a random process that unfolds over time. The stochastic nature implies that, even though the underlying process has certain statistical properties, the specific values observed at any given point in time are not predetermined and can exhibit variability."
  },
  {
    "objectID": "intro.html#stochastic-processes-vs-probaility-calculation-in-a-single-random-variable",
    "href": "intro.html#stochastic-processes-vs-probaility-calculation-in-a-single-random-variable",
    "title": "1  Introduction",
    "section": "1.13 Stochastic processes vs probaility calculation in a single random variable",
    "text": "1.13 Stochastic processes vs probaility calculation in a single random variable"
  },
  {
    "objectID": "intro.html#applications-of-stochastic-processes",
    "href": "intro.html#applications-of-stochastic-processes",
    "title": "1  Introduction",
    "section": "1.14 Applications of stochastic processes",
    "text": "1.14 Applications of stochastic processes"
  },
  {
    "objectID": "chapter2.html#introduction",
    "href": "chapter2.html#introduction",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nA discrete parameter Markov chain process is a modeling approach used to represent systems that evolve over time in discrete steps, where the future state depends only on the current state. This is very useful in analyzing distinct states and transitions. Discrete Parameter Markov Chains is also known as “Discrete-time Markov Chains”.\nDefinition\nLet \\(\\{X_n; n = 0, 1, 2, ...\\}\\) be a stochastic process that takes on a finite or countable number of possible values. If \\(X_n=i,\\) then the process is said to be in state \\(i\\) at time \\(n\\).\nThe discrete-parameter, discrete state stochastic process \\(\\{X_n; n=0, 1, 2,...\\}\\) is called a discrete-parameter Markov chain if for all states \\(i_0, i_1,...i_{n-1}, i, j\\) and all \\(n \\geq 0\\),\n\\[P(X_{n+1}=j|X_n=i, X_{n-1}=i_{n-1}, ..., X_1=i_1, X_0=i_0) = P(X_{n+1}=j|X_n=i).\\]\n\nThis means, a stochastic process is a Markov chain if the probability of moving to the next state depends only on the current state and not on the sequence of events that preceded it."
  },
  {
    "objectID": "chapter2.html#one-step-transition-probabilities",
    "href": "chapter2.html#one-step-transition-probabilities",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.2 One-step transition probabilities",
    "text": "2.2 One-step transition probabilities\nWe have a set of states, \\(S = \\{i_0, i_1, i_2,...i_{n-1}, i, j\\}\\). The process starts in one of these states and moves successively from one state to another. Each move is called a step.\n\\(P_{nij} = P(X_{n+1}=j|X_n=i, X_{n-1}=i_{n-1}, ..., X_1=i_1, X_0=i_0) = P(X_{n+1}=j|X_n=i)\\)\nIf the chain is currently in state \\(i\\), then it moves to state \\(j\\) at the next step with a probability denoted by \\(p_{nij}\\) , and this probability does not depend upon which states the chain was in before the current state.\nThe probabilities \\(p_{nij}\\) are called one-step transition probabilities."
  },
  {
    "objectID": "chapter2.html#one-step-transition-probabilities-1",
    "href": "chapter2.html#one-step-transition-probabilities-1",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.3 One-step transition probabilities",
    "text": "2.3 One-step transition probabilities"
  },
  {
    "objectID": "chapter2.html#chapman-kolmogorov-equations",
    "href": "chapter2.html#chapman-kolmogorov-equations",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.7 Chapman-Kolmogorov equations",
    "text": "2.7 Chapman-Kolmogorov equations\n\\[P_{ij}^{n+m}=\\sum_{k=0}^{\\infty}P_{ik}^nP_{kj}^m\\text{ for all n, m} \\geq 0, \\text{ all i, j,}\\] where, \\(P^n_{ik}P^m_{kj}\\) represents the probability that starting in \\(i\\) the process will go to state \\(j\\) in \\(n+m\\) with an intermediate stop in state \\(k\\) after \\(n\\) steps.\nThis can be used to compute \\(n\\)-step transition probabilities"
  },
  {
    "objectID": "chapter2.html#higher-n-step-transition-probabilities",
    "href": "chapter2.html#higher-n-step-transition-probabilities",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.6 Higher (n-step) transition probabilities",
    "text": "2.6 Higher (n-step) transition probabilities\n\\(P_{ij}\\) - One step transition probabilities\n\\(P^n_{ij}\\) - n - step transition probabilities\nProbability that a process in state \\(i\\) will be in state \\(j\\) after \\(n\\) additional transitions. That is,\n\\[P^n_{ij}=P(X_{n+k}=j|X_k=i), \\text{ } n\\geq 0, \\text{ }i, j \\geq 0.\\]"
  },
  {
    "objectID": "chapter2.html#classification-of-states",
    "href": "chapter2.html#classification-of-states",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.11 Classification of states",
    "text": "2.11 Classification of states"
  },
  {
    "objectID": "chapter2.html#limiting-probabilities",
    "href": "chapter2.html#limiting-probabilities",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.12 Limiting probabilities",
    "text": "2.12 Limiting probabilities"
  },
  {
    "objectID": "chapter2.html#applications",
    "href": "chapter2.html#applications",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.13 Applications",
    "text": "2.13 Applications"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "intro.html#stochastic-process-vs-a-deterministic-process-1",
    "href": "intro.html#stochastic-process-vs-a-deterministic-process-1",
    "title": "1  Introduction",
    "section": "1.13 Stochastic process vs a deterministic process",
    "text": "1.13 Stochastic process vs a deterministic process"
  },
  {
    "objectID": "intro.html#stochastic-proceses-vs-time-series-1",
    "href": "intro.html#stochastic-proceses-vs-time-series-1",
    "title": "1  Introduction",
    "section": "1.14 Stochastic proceses vs Time series",
    "text": "1.14 Stochastic proceses vs Time series\nRealization\nmultiple realizations of a stochastic process."
  },
  {
    "objectID": "chapter2.html#exercise",
    "href": "chapter2.html#exercise",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.4 Exercise",
    "text": "2.4 Exercise\n\nSuppose there are two types of crops (Crop A and Crop B) planted in different fields, and farmers perform certain operations that may affect the composition of crops in each field. After each agricultural season, a random selection of crops from one field is transferred to the other. Let \\(X\\_t\\) denote the number of Crop A plants in the first field after the \\(t\\)th season. What are the parameter space and state space for this agricultural scenario, and can \\(\\{X\\_t\\}\\) be considered a Markov chain given certain conditions on the planting and transfer processes?"
  },
  {
    "objectID": "chapter2.html#one-step-transition-probability-matrix",
    "href": "chapter2.html#one-step-transition-probability-matrix",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.5 One-step transition probability matrix",
    "text": "2.5 One-step transition probability matrix\nLet \\(P\\) denote the matrix of one-step transition probabilities \\(P_{ij}\\), so that\n\\[P = \\left[\\begin{array}{cccccccc}\np_{00} & p_{01} & p_{02} & ...\\\\\np_{10} & p_{11} & p_{12} & ...\\\\\n. & . & . & ...\\\\\np_{i0} & p_{i1} & p_{i2} & ...\\\\\n. & . & . & ...\n\\end{array}\\right]\\]\nSince probabilities are nonnegative and since the process must make a transition into some state, we have\n\\(p_{ij} \\geq 0,\\) for \\(i, j \\geq 0\\), \\(\\sum_{j=0}^\\infty p_{ij} = 1,\\) for \\(i = 0, 1, ...\\)"
  },
  {
    "objectID": "chapter2.html#exercise-1",
    "href": "chapter2.html#exercise-1",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.8 Exercise",
    "text": "2.8 Exercise\n\nShow that \\(P_{ij}^{n+m}=\\sum_{k=0}^{\\infty}P_{ik}^nP_{kj}^m\\text{ for all n, m} \\geq 0, \\text{ all i, j.}\\)"
  },
  {
    "objectID": "chapter2.html#n-step-transition-probabilities---pn_ij",
    "href": "chapter2.html#n-step-transition-probabilities---pn_ij",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.5 \\(n\\)-step transition probabilities - \\(P^n_{ij}\\)",
    "text": "2.5 \\(n\\)-step transition probabilities - \\(P^n_{ij}\\)\n\\(P_{ij}\\) - One step transition probabilities\n\\(P^n_{ij}\\) - n - step transition probabilities\nProbability that a process in state \\(i\\) will be in state \\(j\\) after \\(n\\) additional transitions. That is,\n\\[P^n_{ij}=P(X_{n+k}=j|X_k=i), \\text{ } n\\geq 0, \\text{ }i, j \\geq 0.\\]"
  },
  {
    "objectID": "chapter2.html#n---step-transition-matrix",
    "href": "chapter2.html#n---step-transition-matrix",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.9 \\(n\\) - step transition matrix",
    "text": "2.9 \\(n\\) - step transition matrix\nThe n-step transition matrix is\n\\[\\mathbf{P}^{(n)} = \\left[\\begin{array}\n{rrrr}\nP_{00}^{(n)} & P_{01}^{(n)} & P_{02}^{(n)} & ...\\\\\nP_{10}^{(n)} & P_{11}^{(n)} & P_{12}^{(n)} & ...\\\\\n. & .  & . & ...\\\\\n. & .  & . & ...\\\\\n. & .  & . & ...\\\\\n\\end{array}\\right]\n\\] The Chapman-Kolmogrov equations imply\n\\[\\mathbf{P}^{(n+m)}=P^{(n)}P^{(m)}.\\]\nIn particular,\n\\[\\mathbf{P}^{(2)}=\\mathbf{P}^{(1)}\\mathbf{P}^{(1)}=\\mathbf{P}\\mathbf{P}=\\mathbf{P}^2.\\] By induction,\n\\[\\mathbf{P}^{(n)}=\\mathbf{P}^{(n-1+1)}=\\mathbf{P}^{n-1}\\mathbf{P}=\\mathbf{P}^n.\\]"
  },
  {
    "objectID": "chapter2.html#n---step-transition-matrix-1",
    "href": "chapter2.html#n---step-transition-matrix-1",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.10 \\(n\\) - step transition matrix",
    "text": "2.10 \\(n\\) - step transition matrix\nProposition\n\\[P^{(n)} = P^n = P \\times P \\times P \\times ... \\times P, \\text{ } n \\geq 1.\\] That is, \\(P^{(n)}\\) is equal to \\(P\\) multiplied by itself \\(n\\) times."
  },
  {
    "objectID": "chapter2.html#time-homogeneous-discrete-parameter-markov-chain",
    "href": "chapter2.html#time-homogeneous-discrete-parameter-markov-chain",
    "title": "2  Discrete Parameter Markov Chains",
    "section": "2.3 Time Homogeneous Discrete-Parameter Markov Chain",
    "text": "2.3 Time Homogeneous Discrete-Parameter Markov Chain\nIf the conditional probability \\(P(X_{n+1}=j|X_n=i)\\) does not depend on \\(n\\), then the process is known as time homogeneous Markov chain process or stationary Markov chain process. Then we can write the conditional probability \\(p_{nij}\\) as \\(P_{i,j}\\). Moreover, when there is no risk of confusion, we can write \\(P_{i,j}\\) simply as \\(P_{ij}\\).\n\n2.3.1 Intuition behind time-homogenous Markov chain process\nExample 1:\nSuppose we observe the condition of crop’s soil moisture on every morning. We record the conditions as dry, normal and wet. Let’s denote the states as follows:\n\nstate 0: dry\nstate 1: normal\nstate 2: wet\n\nLet’s assume that the soil moisture condition on a given day depends only on the moisture condition of the previous day. Furthermore, in this case conditional probability \\(P(X_{n+1}=j|X_n=i)\\) actually depend on \\(n\\). The probability of moving wet to wet \\(P(X_{n+1}=2|X_n=2)\\) is not same for the whole year. This probability is small during the dry season and very high during the rainy season. If you are living in a country with four seasons, then this probability will vary according to the seasons: winter, summer, spring, and autumn. Hence, this is a non-stationary discrete-parameter discrete-state space Markov chain process. We can use a stationary Markov chain only for a short period of time.\nIn this book we only consider time-homogeneous Markov chain processes.\nExample 2\nLet’s consider modeling the mood of a person as a time-homogeneous Markov chain with three states:\n\nstate 0: happy\nstate 1: neutral\nstate 2: sad\n\nHere is the time"
  }
]